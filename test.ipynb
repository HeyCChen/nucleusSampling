{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import scatter\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "for step, data in enumerate(loader):\n",
    "    edge_index, batch = data.edge_index, data.batch\n",
    "\n",
    "    x = torch.rand(batch.size(0))\n",
    "    # print(x)\n",
    "\n",
    "    num_nodes = scatter(batch.new_ones(x.size(0)), batch, reduce='sum')\n",
    "    print(num_nodes)\n",
    "    batch_size, max_num_nodes = num_nodes.size(0), int(num_nodes.max())\n",
    "\n",
    "    cum_num_nodes = torch.cat(\n",
    "        [num_nodes.new_zeros(1),\n",
    "         num_nodes.cumsum(dim=0)[:-1]], dim=0)\n",
    "\n",
    "    index = torch.arange(batch.size(0), dtype=torch.long)\n",
    "    # print(index)\n",
    "    # index - cum_num_nodes[batch] 得到的是每个点在各自图中的编号\n",
    "    index = (index - cum_num_nodes[batch]) + (batch * max_num_nodes)\n",
    "    # m = batch * max_num_nodes\n",
    "    # print(index)\n",
    "\n",
    "    dense_x = x.new_full((batch_size * max_num_nodes, ), -60000.0)\n",
    "    # print(dense_x.size())\n",
    "    dense_x[index] = x\n",
    "    # print(x[0:max_num_nodes*3])\n",
    "    # print(dense_x[0:max_num_nodes*3])\n",
    "    dense_x = dense_x.view(batch_size, max_num_nodes)\n",
    "    # print(dense_x[:3])\n",
    "    dense_x = softmax(dense_x)\n",
    "    # print(dense_x[-10:])\n",
    "    probs, perm = dense_x.sort(dim=-1, descending=True)\n",
    "    # print(perm)\n",
    "    cum_probs = torch.cumsum(probs, dim=-1)\n",
    "\n",
    "    nucleus = (cum_probs < 0.5)+0\n",
    "    k = torch.count_nonzero(nucleus, dim=1).reshape(-1)\n",
    "    k = torch.clamp(k, min=1)\n",
    "    perm = perm + cum_num_nodes.view(-1, 1)\n",
    "    # print(perm)\n",
    "    perm = perm.view(-1)\n",
    "\n",
    "    index = torch.cat([\n",
    "        torch.arange(k[i], device=x.device) + i * max_num_nodes\n",
    "        for i in range(batch_size)\n",
    "    ], dim=0)\n",
    "    print(index)\n",
    "\n",
    "    perm = perm[index]\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "softmax = nn.Softmax(dim=-1)\n",
    "temperature = 1.0\n",
    "\n",
    "x = torch.rand(20, 32)\n",
    "x = x/float(temperature)\n",
    "probs, indices = x.sort(dim=-1, descending=True)\n",
    "# print(x)\n",
    "# print(probs)\n",
    "sm = softmax(probs)\n",
    "# print(sm)\n",
    "grad = sm[:, 1:] - sm[:, :-1]\n",
    "grad = grad[:, 1:] - grad[:, :-1]\n",
    "# print(grad)\n",
    "only_pos = torch.abs(grad)\n",
    "sum = torch.sum(only_pos, dim=1).view(-1, 1)\n",
    "sec_weights = only_pos/sum\n",
    "# print(sec_weights)\n",
    "cum_weights = (torch.cumsum(sec_weights, dim=1) > 0.9)+0\n",
    "# print(cum_weights)\n",
    "tail_ids = torch.argmax(cum_weights, dim=1)+1\n",
    "k = torch.clamp(tail_ids, min=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "x = torch.rand(32, 16)\n",
    "sorted_scores, sorted_indices = torch.sort(\n",
    "    x, descending=False, dim=1\n",
    ")\n",
    "# print(x)\n",
    "# print(sorted_scores)\n",
    "cdf = torch.cumsum(sorted_scores, dim=1)\n",
    "# print(cdf)\n",
    "# print(cdf - cdf.min(dim=1)[0].unsqueeze(dim=1))\n",
    "\n",
    "normalized_cdf = (\n",
    "    cdf - cdf.min(dim=1)[0].unsqueeze(dim=1)\n",
    ") / ((cdf.max(dim=1)[0] - cdf.min(dim=1)[0]) / 1.0).unsqueeze(dim=1)\n",
    "# print(normalized_cdf.size())\n",
    "\n",
    "B = normalized_cdf.shape[0]\n",
    "# print(B)\n",
    "\n",
    "n_tokens = int(normalized_cdf.shape[1]/2)\n",
    "# print(n_tokens)\n",
    "\n",
    "ys = (\n",
    "    torch.linspace(\n",
    "        start=0,\n",
    "        end=1.0,\n",
    "        steps=n_tokens,\n",
    "        device=normalized_cdf.device,\n",
    "    )\n",
    "    .unsqueeze(0)\n",
    "    .repeat(B, 1)\n",
    ")\n",
    "# print(ys)\n",
    "\n",
    "ys_start = (\n",
    "    torch.min(normalized_cdf + (normalized_cdf == 0).float() * 1e8, dim=1)[0]\n",
    "    .unsqueeze(-1)\n",
    "    .expand_as(ys)\n",
    ")\n",
    "# print(ys_start)\n",
    "\n",
    "steps = (\n",
    "    torch.range(0, n_tokens - 1, device=normalized_cdf.device)\n",
    "    .unsqueeze(0)\n",
    "    .expand_as(ys_start)\n",
    ")\n",
    "# print(steps)\n",
    "ys = ys_start + (((ys * (n_tokens - 1)) - ys_start * steps) / (n_tokens - 1))\n",
    "ys = ys.unsqueeze(dim=2)\n",
    "# print(ys.size())\n",
    "\n",
    "normalized_cdf = normalized_cdf.unsqueeze(dim=1)\n",
    "# print(normalized_cdf.size())\n",
    "\n",
    "expanded_ys = torch.Tensor.expand(ys, (B, ys.shape[1], ys.shape[1]))\n",
    "# print(expanded_ys.size())\n",
    "\n",
    "N = sorted_scores.shape[1]\n",
    "diff_tokens = ys.shape[1] - N\n",
    "# print(diff_tokens)\n",
    "# print(torch.abs(expanded_ys - F.pad(normalized_cdf, (diff_tokens, 0))))\n",
    "\n",
    "tokens_to_pick_ind = torch.min(\n",
    "    torch.abs(expanded_ys - F.pad(normalized_cdf, (diff_tokens, 0))),\n",
    "    dim=2,\n",
    ")[1]\n",
    "print(tokens_to_pick_ind.size())\n",
    "tokens_to_pick_ind = tokens_to_pick_ind - diff_tokens\n",
    "print(tokens_to_pick_ind)\n",
    "\n",
    "\n",
    "def get_unique_indices(indices: Tensor, max_value: int) -> Tensor:\n",
    "    sorted_indices = torch.sort(indices, dim=1)[0]\n",
    "\n",
    "    shift_left = F.pad(sorted_indices[:, 1:], (0, 1), value=1.0)\n",
    "    unique_indices = torch.where(\n",
    "        (shift_left - sorted_indices) == 0,\n",
    "        max_value * torch.ones_like(indices),\n",
    "        sorted_indices,\n",
    "    )\n",
    "\n",
    "    unique_indices = torch.sort(unique_indices, dim=1)[0]\n",
    "\n",
    "    return unique_indices\n",
    "\n",
    "\n",
    "unique_indices = get_unique_indices(\n",
    "    indices=tokens_to_pick_ind, max_value=N - 1\n",
    ")  # [B x n_tokens]\n",
    "\n",
    "\n",
    "raw_indice = torch.gather(\n",
    "    sorted_indices, 1, unique_indices\n",
    ")\n",
    "\n",
    "print(raw_indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import random\n",
    "\n",
    "x = torch.arange(8)\n",
    "print(x)\n",
    "y = torch.rand(8)\n",
    "print(y)\n",
    "cdf_y = torch.cumsum(y, dim=-1)\n",
    "cdf_y = cdf_y/cdf_y.max()\n",
    "print(cdf_y)\n",
    "out = interpolate.interp1d(cdf_y, x)\n",
    "uniform_samples = random(int(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "N = 17\n",
    "Max = 35\n",
    "ratio = 0.5\n",
    "\n",
    "a = torch.rand(N)\n",
    "# print(a)\n",
    "x = a.new_full((1 * Max, ), -60000.0)\n",
    "# print(x)\n",
    "index = torch.arange(17)\n",
    "x[index] = a\n",
    "# print(x)\n",
    "sm = softmax(x)\n",
    "# print(sm)\n",
    "cdf = torch.cumsum(sm, dim=-1)\n",
    "# print(cdf)\n",
    "\n",
    "normalized_cdf = (\n",
    "    cdf - cdf.min(dim=0)[0]\n",
    ") / ((cdf.max(dim=0)[0] - cdf.min(dim=0)[0]) / 1.0)\n",
    "print(normalized_cdf)\n",
    "\n",
    "T = int(ratio*N)\n",
    "\n",
    "ys = torch.linspace(\n",
    "    start=0,\n",
    "    end=1.0,\n",
    "    steps=T+2,\n",
    ")[1:T+1].view(-1, 1)\n",
    "print(ys)\n",
    "\n",
    "pre_cdf = normalized_cdf.repeat(T, 1)\n",
    "# print(pre_cdf)\n",
    "print((pre_cdf > ys)+0)\n",
    "pre_selected = torch.argmax((pre_cdf > ys)+0, dim=1)\n",
    "print(pre_selected)\n",
    "xxx = torch.arange(10)\n",
    "out = torch.cat([pre_selected, xxx])\n",
    "indexx = torch.arange(5)\n",
    "print(out)\n",
    "pee = out[indexx]\n",
    "print(pee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2])\n",
      "tensor([9, 8, 7, 6, 5, 4, 3, 2, 1, 0])\n",
      "tensor([7])\n"
     ]
    }
   ],
   "source": [
    "a, perm = torch.arange(10).sort(dim=0, descending=True)\n",
    "b = torch.tensor([2, 2])\n",
    "print(b)\n",
    "print(a)\n",
    "print(a[b].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
