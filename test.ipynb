{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1144]) torch.Size([1144]) torch.Size([1144]) torch.Size([1144]) tensor(2994)\n",
      "tensor(11)\n",
      "tensor([[0, 1, 0, 0],\n",
      "        [0, 1, 1, 1],\n",
      "        [0, 1, 1, 0],\n",
      "        [0, 0, 1, 1],\n",
      "        [1, 0, 1, 1]])\n",
      "tensor([1, 3, 2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import scatter\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for step, data in enumerate(loader):\n",
    "    edge_index, batch = data.edge_index, data.batch\n",
    "    # print(batch.new_ones(x.size(0)))\n",
    "    # m = edge_index.new_zeros(x.size(0))\n",
    "\n",
    "    x = torch.rand(batch.size(0))\n",
    "    # print(x.size())\n",
    "\n",
    "    num_nodes = scatter(batch.new_ones(x.size(0)), batch, reduce='sum')\n",
    "    # print(num_nodes)\n",
    "    batch_size, max_num_nodes = num_nodes.size(0), int(num_nodes.max())\n",
    "\n",
    "    cum_num_nodes = torch.cat(\n",
    "        [num_nodes.new_zeros(1),\n",
    "         num_nodes.cumsum(dim=0)[:-1]], dim=0)\n",
    "\n",
    "    # print(num_nodes)\n",
    "    # print(cum_num_nodes)\n",
    "    # print(cum_num_nodes[batch])\n",
    "\n",
    "    index = torch.arange(batch.size(0), dtype=torch.long)\n",
    "    index = (index - cum_num_nodes[batch]) + (batch * max_num_nodes)\n",
    "    m = batch * max_num_nodes\n",
    "    # print(index.size())\n",
    "    # print(m)\n",
    "    print(m.size(), index.size(), batch.size(), x.size(), index.max())\n",
    "    # print(index, index.size())\n",
    "    # print(batch_size * max_num_nodes)\n",
    "    # print(max_num_nodes)\n",
    "    # print(index, index.size())\n",
    "    # print((batch * max_num_nodes).size())\n",
    "\n",
    "    dense_x = x.new_full((batch_size * max_num_nodes, ), -60000.0)\n",
    "    # print(dense_x.size())\n",
    "    dense_x[index] = x\n",
    "    dense_x = dense_x.view(batch_size, max_num_nodes)\n",
    "    # print(dense_x.size())\n",
    "    # print(x.size())\n",
    "\n",
    "    # k = (float(0.8) * num_nodes.to(x.dtype)).ceil().to(torch.long)\n",
    "    # print(num_nodes)\n",
    "    # print(k)\n",
    "    # id = torch.cat([\n",
    "    #     torch.arange(k[i]) + i * max_num_nodes\n",
    "    #     for i in range(batch_size)\n",
    "    # ], dim=0)\n",
    "\n",
    "    # print(id,id.size())\n",
    "\n",
    "    sm = nn.Softmax(dim=-1)\n",
    "\n",
    "    nu = torch.rand(20).view(5, 4)\n",
    "\n",
    "    out = (nu < 0.5)+0\n",
    "    print((out == True).sum())\n",
    "    nz = torch.count_nonzero(out, dim=1).reshape(-1)\n",
    "    print(out)\n",
    "    print(nz)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
